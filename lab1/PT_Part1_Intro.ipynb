{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBk0ZDWY-ff8"
      },
      "source": [
        "<table align=\"center\">\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"http://introtodeeplearning.com\">\n",
        "        <img src=\"https://i.ibb.co/Jr88sn2/mit.png\" style=\"padding-bottom:5px;\" />\n",
        "      Visit MIT Deep Learning</a></td>\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/MITDeepLearning/introtodeeplearning/blob/master/lab1/PT_Part1_Intro.ipynb\">\n",
        "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/MITDeepLearning/introtodeeplearning/blob/master/lab1/PT_Part1_Intro.ipynb\">\n",
        "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
        "</table>\n",
        "\n",
        "# Copyright Information\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eI6DUic-6jo"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 MIT Introduction to Deep Learning. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the MIT License. You may not use this file except in compliance\n",
        "# with the License. Use and/or modification of this code outside of MIT Introduction\n",
        "# to Deep Learning must reference:\n",
        "#\n",
        "# © MIT Introduction to Deep Learning\n",
        "# http://introtodeeplearning.com\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57knM8jrYZ2t"
      },
      "source": [
        "# Lab 1: Intro to PyTorch and Music Generation with RNNs\n",
        "\n",
        "In this lab, you'll get exposure to using PyTorch and learn how it can be used for deep learning. Go through the code and run each cell. Along the way, you'll encounter several ***TODO*** blocks -- follow the instructions to fill them out before running those cells and continuing.\n",
        "\n",
        "\n",
        "# Part 1: Intro to PyTorch\n",
        "\n",
        "## 0.1 Install PyTorch\n",
        "\n",
        "[PyTorch](https://pytorch.org/) is a popular deep learning library known for its flexibility and ease of use. Here we'll learn how computations are represented and how to define a simple neural network in PyTorch. For all the labs in Introduction to Deep Learning 2025, there will be a PyTorch version available.\n",
        "\n",
        "Let's install PyTorch and a couple of dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LkaimNJfYZ2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d9c6cf-c102-41ca-9296-3255a0bb585d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/2.8 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m658.2/658.2 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m833.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m132.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.1/66.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for mitdeeplearning (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Download and import the MIT Introduction to Deep Learning package\n",
        "!pip install mitdeeplearning --quiet\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QNMcdP4m3Vs"
      },
      "source": [
        "## 1.1 What is PyTorch?\n",
        "\n",
        "PyTorch is a machine learning library, like TensorFlow. At its core, PyTorch provides an interface for creating and manipulating [tensors](https://pytorch.org/docs/stable/tensors.html), which are data structures that you can think of as multi-dimensional arrays. Tensors are represented as n-dimensional arrays of base datatypes such as a string or integer -- they provide a way to generalize vectors and matrices to higher dimensions. PyTorch provides the ability to perform computation on these tensors, define neural networks, and train them efficiently.\n",
        "\n",
        "The [```shape```](https://pytorch.org/docs/stable/generated/torch.Tensor.shape.html#torch.Tensor.shape) of a PyTorch tensor defines its number of dimensions and the size of each dimension. The `ndim` or [```dim```](https://pytorch.org/docs/stable/generated/torch.Tensor.dim.html#torch.Tensor.dim) of a PyTorch tensor provides the number of dimensions (n-dimensions) -- this is equivalent to the tensor's rank (as is used in TensorFlow), and you can also think of this as the tensor's order or degree.\n",
        "\n",
        "Let’s start by creating some tensors and inspecting their properties:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFxztZQInlAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b7bfdf4-0447-4aed-9974-0c5c40bf5fbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`integer` is a 0-d Tensor: 1234\n",
            "`decimal` is a 0-d Tensor: 3.1415927410125732\n"
          ]
        }
      ],
      "source": [
        "integer = torch.tensor(1234)\n",
        "decimal = torch.tensor(3.14159265359)\n",
        "\n",
        "print(f\"`integer` is a {integer.ndim}-d Tensor: {integer}\")\n",
        "print(f\"`decimal` is a {decimal.ndim}-d Tensor: {decimal}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dljcPUcoJZ6"
      },
      "source": [
        "Vectors and lists can be used to create 1-d tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaHXABe8oPcO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5edec8e0-4942-4513-93b0-1fa4946984b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`fibonacci` is a 1-d Tensor with shape: torch.Size([6])\n",
            "`count_to_100` is a 1-d Tensor with shape: torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "fibonacci = torch.tensor([1, 1, 2, 3, 5, 8])\n",
        "count_to_100 = torch.tensor(range(100))\n",
        "\n",
        "print(f\"`fibonacci` is a {fibonacci.ndim}-d Tensor with shape: {fibonacci.shape}\")\n",
        "print(f\"`count_to_100` is a {count_to_100.ndim}-d Tensor with shape: {count_to_100.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvffwkvtodLP"
      },
      "source": [
        "Next, let’s create 2-d (i.e., matrices) and higher-rank tensors. In image processing and computer vision, we will use 4-d Tensors with dimensions corresponding to batch size, number of color channels, image height, and image width."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tFeBBe1IouS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b53a5a32-b53d-42be-c461-a94a98cb38c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`matrix` is a 2-d Tensor with shape: torch.Size([2, 1])\n",
            "`images` is a 4-d Tensor with shape: torch.Size([10, 3, 256, 256])\n",
            "images is a 4-d Tensor with shape: torch.Size([10, 3, 256, 256])\n",
            "torch.Size([2, 2])\n",
            "torch.Size([2, 3])\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[1, 2, 3],\n",
            "         [3, 4, 5]],\n",
            "\n",
            "        [[1, 2, 3],\n",
            "         [3, 4, 5]]])\n"
          ]
        }
      ],
      "source": [
        "### Defining higher-order Tensors ###\n",
        "\n",
        "'''TODO: Define a 2-d Tensor'''\n",
        "matrix = torch.tensor([[1],[2]])\n",
        "print(f\"`matrix` is a {matrix.ndim}-d Tensor with shape: {matrix.shape}\")\n",
        "\n",
        "assert isinstance(matrix, torch.Tensor), \"matrix must be a torch Tensor object\"\n",
        "assert matrix.ndim == 2\n",
        "\n",
        "'''TODO: Define a 4-d Tensor.'''\n",
        "# Use torch.zeros to initialize a 4-d Tensor of zeros with size 10 x 3 x 256 x 256.\n",
        "#   You can think of this as 10 images where each image is RGB 256 x 256.\n",
        "# images = torch.tensor([[[1]]])\n",
        "images = torch.zeros(10, 3, 256, 256)\n",
        "print(f\"`images` is a {images.ndim}-d Tensor with shape: {images.shape}\")\n",
        "\n",
        "assert isinstance(images, torch.Tensor), \"images must be a torch Tensor object\"\n",
        "assert images.ndim == 4, \"images must have 4 dimensions\"\n",
        "assert images.shape == (10, 3, 256, 256), \"images is incorrect shape\"\n",
        "print(f\"images is a {images.ndim}-d Tensor with shape: {images.shape}\")\n",
        "\n",
        "data = [[1, 2], [3, 4]]\n",
        "my_tensor = torch.tensor(data)\n",
        "print(my_tensor.shape)\n",
        "\n",
        "data2 = [[1, 2, 3], [3, 4, 5]]\n",
        "my_tensor2 = torch.tensor(data2)\n",
        "print(my_tensor2.shape)\n",
        "\n",
        "data3 = [[[1, 2, 3], [3, 4, 5]],[[1, 2, 3], [3, 4, 5]]]\n",
        "my_tensor3 = torch.tensor(data3)\n",
        "print(my_tensor3.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tensor\n",
        "tensor 可以理解为一个a * b * c * ... 的n维元素\n",
        "\n",
        "- **0维 tensor：** 一个标量或单个数字。\n",
        "- **1维 tensor：** 一个向量。\n",
        "- **2维 tensor：** 一个矩阵。\n",
        "- **3维及以上 tensor：** 通常就直接称为 tensor。 例如，一张彩色图片可以表示为一个 3D tensor（高度 x 宽度 x 通道数）。\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "data = [[1, 2], [3, 4]]\n",
        "my_tensor = torch.tensor(data)\n",
        "```\n",
        "\n",
        "这个 `my_tensor` 对象具有以下几个关键属性：\n",
        "\n",
        "#### 1. 维度 (Dimensions)\n",
        "\n",
        "这个 tensor 是一个 **二维 (2D) tensor**，通常也被称为 **矩阵**。\n",
        "\n",
        "*   **直观理解**：您提供的 `data` 是一个列表，其内部包含了两个列表 `[1, 2]` 和 `[3, 4]`。您可以把外层的列表看作是矩阵的 “行”，内层的列表看作是每一 “行” 中的元素。\n",
        "    *   第一行是 `[1, 2]`\n",
        "    *   第二行是 `[3, 4]`\n",
        "*   **秩 (Rank)**：在 tensor 的术语中，维度 (dimension) 的数量被称为 “秩” (rank)。因此，这是一个秩为 2 的 tensor。\n",
        "\n",
        "#### 2. 形状 (Shape)\n",
        "\n",
        "这个 tensor 的形状是 `(2, 2)`，更确切地说是 `torch.Size([2, 2])`。\n",
        "\n",
        "*   **含义**：形状描述了 tensor 在每个维度上的大小。\n",
        "    *   第一个维度的大小是 2，表示它有 2 行。\n",
        "    *   第二个维度的大小是 2，表示它有 2 列。\n",
        "\n",
        "您可以通过访问 `.shape` 属性来验证这一点：\n",
        "```python\n",
        "print(my_tensor.shape)\n",
        "# 输出: torch.Size([2, 2])\n",
        "```\n",
        "\n",
        "#### 3. 数据类型 (dtype)\n",
        "\n",
        "当您用一个只包含整数的 Python 列表来创建 tensor 时，PyTorch 的 `torch.tensor()` 函数会自动推断数据类型。\n",
        "\n",
        "*   **默认整数类型**：对于整数，PyTorch 会默认使用 `torch.int64`。 这是一种64位的有符号整数类型，可以表示非常大范围的整数。\n",
        "\n",
        "您可以通过访问 `.dtype` 属性来查看：\n",
        "```python\n",
        "print(my_tensor.dtype)\n",
        "# 输出: torch.int64\n",
        "```\n",
        "*   **注意**：如果您的原始数据中包含至少一个浮点数（例如 `[[1.0, 2], [3, 4]]`），那么整个 tensor 的数据类型就会被推断为浮点型，默认为 `torch.float32`。\n"
      ],
      "metadata": {
        "id": "DUfnJtpX9Pt-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkaCDOGapMyl"
      },
      "source": [
        "As you have seen, the `shape` of a tensor provides the number of elements in each tensor dimension. The `shape` is quite useful, and we'll use it often. You can also use slicing to access subtensors within a higher-rank tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhaufyObuLEG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "53db176a-d3c6-49ef-f30b-ab4c466d62b4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 1 is out of bounds for dimension 1 with size 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-18-2116781199.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrow_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcolumn_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mscalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"`row_vector`: {row_vector}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 1 with size 1"
          ]
        }
      ],
      "source": [
        "row_vector = matrix[1]\n",
        "column_vector = matrix[:, 1]\n",
        "scalar = matrix[0, 1]\n",
        "\n",
        "print(f\"`row_vector`: {row_vector}\")\n",
        "print(f\"`column_vector`: {column_vector}\")\n",
        "print(f\"`scalar`: {scalar}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD3VO-LZYZ2z"
      },
      "source": [
        "## 1.2 Computations on Tensors\n",
        "\n",
        "A convenient way to think about and visualize computations in a machine learning framework like PyTorch is in terms of graphs. We can define this graph in terms of tensors, which hold data, and the mathematical operations that act on these tensors in some order. Let's look at a simple example, and define this computation using PyTorch:\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/MITDeepLearning/introtodeeplearning/2025/lab1/img/add-graph.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X_YJrZsxYZ2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb1c133-cf85-4813-d5ad-22df743b48e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c1: 76\n",
            "c2: 76\n"
          ]
        }
      ],
      "source": [
        "# Create the nodes in the graph and initialize values\n",
        "a = torch.tensor(15)\n",
        "b = torch.tensor(61)\n",
        "\n",
        "# Add them!\n",
        "c1 = torch.add(a, b)\n",
        "c2 = a + b  # PyTorch overrides the \"+\" operation so that it is able to act on Tensors\n",
        "print(f\"c1: {c1}\")\n",
        "print(f\"c2: {c2}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbfv_QOiYZ23"
      },
      "source": [
        "Notice how we've created a computation graph consisting of PyTorch operations, and how the output is a tensor with value 76 -- we've just created a computation graph consisting of operations, and it's executed them and given us back the result.\n",
        "\n",
        "Now let's consider a slightly more complicated example:\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/MITDeepLearning/introtodeeplearning/2025/lab1/img/computation-graph.png)\n",
        "\n",
        "Here, we take two inputs, `a, b`, and compute an output `e`. Each node in the graph represents an operation that takes some input, does some computation, and passes its output to another node.\n",
        "\n",
        "Let's define a simple function in PyTorch to construct this computation function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PJnfzpWyYZ23",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "### Defining Tensor computations ###\n",
        "\n",
        "# Construct a simple computation function\n",
        "def func(a, b):\n",
        "    '''TODO: Define the operation for c, d, e.'''\n",
        "    c = torch.add(a, b)\n",
        "    d = torch.sub(b, 1)\n",
        "    e = torch.mul(c, d)\n",
        "    return e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwrRfDMS2-oy"
      },
      "source": [
        "Now, we can call this function to execute the computation graph given some inputs `a,b`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pnwsf8w2uF7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f2b7778-0727-48b5-9cbb-cfdb617687fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e_out: 6.0\n"
          ]
        }
      ],
      "source": [
        "# Consider example values for a,b\n",
        "a, b = 1.5, 2.5\n",
        "# Execute the computation\n",
        "e_out = func(a, b)\n",
        "print(f\"e_out: {e_out}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HqgUIUhYZ29"
      },
      "source": [
        "Notice how our output is a tensor with value defined by the output of the computation, and that the output has no shape as it is a single scalar value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h4o9Bb0YZ29"
      },
      "source": [
        "## 1.3 Neural networks in PyTorch\n",
        "We can also define neural networks in PyTorch. PyTorch uses [``torch.nn.Module``](https://pytorch.org/docs/stable/generated/torch.nn.Module.html), which serves as a base class for all neural network modules in PyTorch and thus provides a framework for building and training neural networks.\n",
        "\n",
        "Let's consider the example of a simple perceptron defined by just one dense (aka fully-connected or linear) layer: $ y = \\sigma(Wx + b) $, where $W$ represents a matrix of weights, $b$ is a bias, $x$ is the input, $\\sigma$ is the sigmoid activation function, and $y$ is the output.\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/MITDeepLearning/introtodeeplearning/2025/lab1/img/computation-graph-2.png)\n",
        "\n",
        "We will use `torch.nn.Module` to define layers -- the building blocks of neural networks. Layers implement common neural networks operations. In PyTorch, when we implement a layer, we subclass `nn.Module` and define the parameters of the layer as attributes of our new class. We also define and override a function [``forward``](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.forward), which will define the forward pass computation that is performed at every step. All classes subclassing `nn.Module` should override the `forward` function.\n",
        "\n",
        "Let's write a dense layer class to implement a perceptron defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HutbJk-1kHPh"
      },
      "outputs": [],
      "source": [
        "### Defining a dense layer ###\n",
        "\n",
        "# num_inputs: number of input nodes\n",
        "# num_outputs: number of output nodes\n",
        "# x: input to the layer\n",
        "\n",
        "class OurDenseLayer(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super(OurDenseLayer, self).__init__()\n",
        "        # Define and initialize parameters: a weight matrix W and bias b\n",
        "        # Note that the parameter initialize is random!\n",
        "        self.W = torch.nn.Parameter(torch.randn(num_inputs, num_outputs))\n",
        "        self.bias = torch.nn.Parameter(torch.randn(num_outputs))\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''TODO: define the operation for z (hint: use torch.matmul).'''\n",
        "        z = torch.matmul(x, self.W) + self.bias\n",
        "\n",
        "        '''TODO: define the operation for out (hint: use torch.sigmoid).'''\n",
        "        y = torch.sigmoid(z)\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqeEbn959hV_"
      },
      "source": [
        "Now, let's test the output of our layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2yxjCPa69hV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de721da-2ec1-459d-d690-2c3089623b07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: torch.Size([1, 2])\n",
            "output shape: torch.Size([1, 3])\n",
            "output result: tensor([[0.1999, 0.9628, 0.4276]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Define a layer and test the output!\n",
        "num_inputs = 2\n",
        "num_outputs = 3\n",
        "layer = OurDenseLayer(num_inputs, num_outputs)\n",
        "x_input = torch.tensor([[1, 2.]])\n",
        "y = layer(x_input)\n",
        "\n",
        "print(f\"input shape: {x_input.shape}\")\n",
        "print(f\"output shape: {y.shape}\")\n",
        "print(f\"output result: {y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt1FgM7qYZ3D"
      },
      "source": [
        "Conveniently, PyTorch has defined a number of ```nn.Modules``` (or Layers) that are commonly used in neural networks, for example a [```nn.Linear```](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) or [`nn.Sigmoid`](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html) module.\n",
        "\n",
        "Now, instead of using a single ```Module``` to define our simple neural network, we'll use the  [`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) module from PyTorch and a single [`nn.Linear` ](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) layer to define our network. With the `Sequential` API, you can readily create neural networks by stacking together layers like building blocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7WXTpmoL6TDz"
      },
      "outputs": [],
      "source": [
        "### Defining a neural network using the PyTorch Sequential API ###\n",
        "\n",
        "# define the number of inputs and outputs\n",
        "n_input_nodes = 2\n",
        "n_output_nodes = 3\n",
        "\n",
        "# Define the model\n",
        "'''TODO: Use the Sequential API to define a neural network with a\n",
        "    single linear (dense!) layer, followed by non-linearity to compute z'''\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_input_nodes,n_output_nodes),\n",
        "    nn.Sigmoid()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDGcwYfUyR-U"
      },
      "source": [
        "We've defined our model using the Sequential API. Now, we can test it out using an example input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zKhp6XqCFFa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0276b13a-833a-43bb-a298-f37d102d3b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: torch.Size([1, 2])\n",
            "output shape: torch.Size([1, 3])\n",
            "output result: tensor([[0.4261, 0.3152, 0.4634]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Test the model with example input\n",
        "x_input = torch.tensor([[1, 2.]])\n",
        "model_output = model(x_input)\n",
        "print(f\"input shape: {x_input.shape}\")\n",
        "print(f\"output shape: {model_output.shape}\")\n",
        "print(f\"output result: {model_output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.Sequential\n",
        "\n",
        "这段代码的核心是 **`nn.Sequential`**，你可以把它理解为一个 **“有序的模块容器”** 或一个 **“流水线”**。\n",
        "\n",
        "---\n",
        "\n",
        "#### 1. `model` 对象是如何创建的？\n",
        "\n",
        "当你写下这行代码时：\n",
        "\n",
        "```python\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_input_nodes, n_output_nodes),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "```\n",
        "\n",
        "你正在创建一个 `nn.Sequential` 类的实例（对象），并将其命名为 `model`。\n",
        "\n",
        "**`nn.Sequential` 的工作机制：**\n",
        "\n",
        "它接收一系列的 PyTorch 模块 (`nn.Module`) 作为输入，并把它们按照你传入的顺序链接起来。在这个例子中，你传入了两个模块：\n",
        "\n",
        "1.  **`nn.Linear(n_input_nodes, n_output_nodes)`**:\n",
        "    *   这正是 PyTorch 官方提供的、预先构建好的 **全连接层（密集层）**。它和我们之前定义的 `OurDenseLayer` 在功能上是完全一样的。\n",
        "    *   当你创建 `nn.Linear(2, 3)` 时，PyTorch 在其内部自动地、高效地完成了定义和初始化权重矩阵 `W` (形状为 `2x3`) 和偏置向量 `bias` (长度为 3) 的所有工作。你不再需要手动去写 `torch.nn.Parameter(torch.randn(...))`。\n",
        "    *   它本身就是一个 `nn.Module` 对象。\n",
        "\n",
        "2.  **`nn.Sigmoid()`**:\n",
        "    *   这是 PyTorch 官方提供的 `Sigmoid` 激活函数。\n",
        "    *   虽然它没有可学习的参数（权重），但在 PyTorch 中，激活函数也被封装成了 `nn.Module` 对象，以便能无缝地插入到像 `nn.Sequential` 这样的容器中。\n",
        "\n",
        "**所以，`model` 对象是一个特殊的容器模块，它内部按顺序包含了两个子模块：一个线性层和一个 Sigmoid 层。**\n",
        "\n",
        "**与 `OurDenseLayer` 的对比:**\n",
        "\n",
        "*   在 `OurDenseLayer` 中，你把 **线性变换 (`xW+b`)** 和 **激活函数 (`sigmoid`)** 这两个步骤的逻辑都写在了同一个 `forward` 方法里。\n",
        "*   在使用 `nn.Sequential` 时，你将这两个步骤分解成了两个独立的、可插拔的模块 (`nn.Linear`, `nn.Sigmoid`)，然后把它们放进一个容器里。这种方式更加模块化，也更容易构建更深、更复杂的网络（只需在 `nn.Sequential` 中添加更多的层即可）。\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. `model()` 又调用了什么功能？\n",
        "\n",
        "这里的原理和之前完全一样：`model` 是一个 `nn.Module` 的子类（因为 `nn.Sequential` 本身就继承自 `nn.Module`），所以调用 `model(x_input)` 会触发其内部的 `__call__` 方法，而 `__call__` 方法会负责调用 `model.forward(x_input)`。\n",
        "\n",
        "**那么 `nn.Sequential` 的 `forward` 方法做了什么呢？**\n",
        "\n",
        "它的 `forward` 方法被设计得非常智能：它会像流水线一样，**自动地、按顺序地** 将输入数据传递给它所包含的每一个子模块。\n",
        "\n",
        "整个过程如下：\n",
        "\n",
        "1.  **输入**: `x_input` (形状 `[1, 2]`) 被传递给 `model`。\n",
        "\n",
        "2.  **第一站：`nn.Linear` 层**:\n",
        "    *   `nn.Sequential` 首先将 `x_input` 传递给它的第一个子模块，也就是 `nn.Linear(2, 3)`。\n",
        "    *   这个线性层执行了 `xW + b` 的计算。\n",
        "    *   它产生了一个 **中间输出** (我们称之为 `z`)，形状为 `[1, 3]`。\n",
        "\n",
        "3.  **第二站：`nn.Sigmoid` 层**:\n",
        "    *   `nn.Sequential` 拿到上一步的输出 `z`，然后 **自动地** 将它作为输入传递给它的第二个子模块，也就是 `nn.Sigmoid()`。\n",
        "    *   `Sigmoid` 层对 `z` 中的每个元素执行 `sigmoid` 运算。\n",
        "    *   它产生了 **最终输出** (我们称之为 `y` 或 `model_output`)，形状仍然是 `[1, 3]`。\n",
        "\n",
        "4.  **返回**: `nn.Sequential` 将这最后的输出作为整个 `model(x_input)` 调用的结果返回。\n",
        "\n",
        "#### 总结\n",
        "\n",
        "*   **`model` 是如何创建的？** 通过 `nn.Sequential` 这个容器，它像一个乐高积木盒，你把各种预制好的模块（如 `nn.Linear`, `nn.Sigmoid`）按顺序放进去。\n",
        "*   **`model()` 调用了什么？** 它调用了 `nn.Sequential` 的 `forward` 方法，该方法会建立一条数据流水线，让输入数据自动地、依次地流过容器内的每一个子模块，并将最后一个模块的输出作为最终结果返回。"
      ],
      "metadata": {
        "id": "yXi6Y5Nw_TNw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "596NvsOOtr9F"
      },
      "source": [
        "With PyTorch, we can create more flexible models by subclassing [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). The `nn.Module` class allows us to group layers together flexibly to define new architectures.\n",
        "\n",
        "As we saw earlier with `OurDenseLayer`, we can subclass `nn.Module` to create a class for our model, and then define the forward pass through the network using the `forward` function. Subclassing affords the flexibility to define custom layers, custom training loops, custom activation functions, and custom models. Let's define the same neural network model as above (i.e., Linear layer with an activation function after it), now using subclassing and using PyTorch's built in linear layer from `nn.Linear`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "K4aCflPVyViD"
      },
      "outputs": [],
      "source": [
        "### Defining a model using subclassing ###\n",
        "\n",
        "class LinearWithSigmoidActivation(nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super(LinearWithSigmoidActivation, self).__init__()\n",
        "        '''TODO: define a model with a single Linear layer and sigmoid activation.'''\n",
        "        self.linear = nn.Linear(num_inputs,num_outputs)\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        linear_output = self.linear(inputs)\n",
        "        output = self.activation(linear_output)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goKCQ9dEGzRn"
      },
      "source": [
        "Let's test out our new model, using an example input, setting `n_input_nodes=2` and `n_output_nodes=3` as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "V-eNhSyRG6hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24eeb283-e8f3-4b62-f5bd-9ff43ace74ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: torch.Size([1, 2])\n",
            "output shape: torch.Size([1, 3])\n",
            "output result: tensor([[0.7272, 0.2186, 0.2001]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "n_input_nodes = 2\n",
        "n_output_nodes = 3\n",
        "model = LinearWithSigmoidActivation(n_input_nodes, n_output_nodes)\n",
        "x_input = torch.tensor([[1, 2.]])\n",
        "y = model(x_input)\n",
        "print(f\"input shape: {x_input.shape}\")\n",
        "print(f\"output shape: {y.shape}\")\n",
        "print(f\"output result: {y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTIFMJLAzsyE"
      },
      "source": [
        "Importantly, `nn.Module` affords us a lot of flexibility to define custom models. For example, we can use boolean arguments in the `forward` function to specify different network behaviors, for example different behaviors during training and inference. Let's suppose under some instances we want our network to simply output the input, without any perturbation. We define a boolean argument `isidentity` to control this behavior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "P7jzGX5D1xT5"
      },
      "outputs": [],
      "source": [
        "### Custom behavior with subclassing nn.Module ###\n",
        "\n",
        "class LinearButSometimesIdentity(nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super(LinearButSometimesIdentity, self).__init__()\n",
        "        self.linear = nn.Linear(num_inputs, num_outputs)\n",
        "\n",
        "    '''TODO: Implement the behavior where the network outputs the input, unchanged,\n",
        "        under control of the isidentity argument.'''\n",
        "    def forward(self, inputs, isidentity=False):\n",
        "      if isidentity:\n",
        "        return inputs\n",
        "      else :\n",
        "        return self.linear(inputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku4rcCGx5T3y"
      },
      "source": [
        "Let's test this behavior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "NzC0mgbk5dp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040c7db3-26a5-4697-81ca-8eacd622433e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: tensor([[1., 2.]])\n",
            "Network linear output: tensor([[ 0.8322,  0.8821, -0.0493]], grad_fn=<AddmmBackward0>); network identity output: tensor([[1., 2.]])\n"
          ]
        }
      ],
      "source": [
        "# Test the IdentityModel\n",
        "model = LinearButSometimesIdentity(num_inputs=2, num_outputs=3)\n",
        "x_input = torch.tensor([[1, 2.]])\n",
        "\n",
        "'''TODO: pass the input into the model and call with and without the input identity option.'''\n",
        "out_with_linear = model(x_input)\n",
        "\n",
        "out_with_identity = model(x_input, isidentity=True)\n",
        "\n",
        "print(f\"input: {x_input}\")\n",
        "print(\"Network linear output: {}; network identity output: {}\".format(out_with_linear, out_with_identity))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V1dEqdk6VI5"
      },
      "source": [
        "Now that we have learned how to define layers and models in PyTorch using both the Sequential API and subclassing `nn.Module`, we're ready to turn our attention to how to actually implement network training with backpropagation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQwDhKn8kbO2"
      },
      "source": [
        "## 1.4 Automatic Differentiation in PyTorch\n",
        "\n",
        "In PyTorch, [`torch.autograd`](https://pytorch.org/docs/stable/autograd.html) is used for [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation), which is critical for training deep learning models with [backpropagation](https://en.wikipedia.org/wiki/Backpropagation).\n",
        "\n",
        "We will use the PyTorch [`.backward()`](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html) method to trace operations for computing gradients. On a tensor, the [`requires_grad`](https://pytorch.org/docs/stable/generated/torch.Tensor.requires_grad_.html) attribute controls whether autograd should record operations on that tensor. When a forward pass is made through the network, PyTorch builds a computational graph dynamically; then, to compute the gradient, the `backward()` method is called to perform backpropagation.\n",
        "\n",
        "Let's compute the gradient of $ y = x^2 $:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "tdkqk8pw5yJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9bf95e8-7b6a-4756-bd75-5068ff8d3347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy_dx of y=x^2 at x=3.0 is:  tensor(6.)\n"
          ]
        }
      ],
      "source": [
        "### Gradient computation ###\n",
        "\n",
        "# y = x^2\n",
        "# Example: x = 3.0\n",
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "y = x ** 2\n",
        "y.backward()  # Compute the gradient\n",
        "\n",
        "dy_dx = x.grad\n",
        "print(\"dy_dx of y=x^2 at x=3.0 is: \", dy_dx)\n",
        "assert dy_dx == 6.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhU5metS5xF3"
      },
      "source": [
        "In training neural networks, we use differentiation and stochastic gradient descent (SGD) to optimize a loss function. Now that we have a sense of how PyTorch's autograd can be used to compute and access derivatives, we will look at an example where we use automatic differentiation and SGD to find the minimum of $ L=(x-x_f)^2 $. Here $x_f$ is a variable for a desired value we are trying to optimize for; $L$ represents a loss that we are trying to minimize. While we can clearly solve this problem analytically ($ x_{min}=x_f $), considering how we can compute this using PyTorch's autograd sets us up nicely for future labs where we use gradient descent to optimize entire neural network losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "attributes": {
          "classes": [
            "py"
          ],
          "id": ""
        },
        "id": "7g1yWiSXqEf-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "b322b15b-017f-425a-ca15-5091bebaf303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing x=-0.43738171458244324\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "### Function minimization with autograd and gradient descent ###\n",
        "\n",
        "# Initialize a random value for our intial x\n",
        "x = torch.randn(1)\n",
        "print(f\"Initializing x={x.item()}\")\n",
        "\n",
        "learning_rate = 1e-2  # Learning rate\n",
        "history = []\n",
        "x_f = 4  # Target value\n",
        "\n",
        "\n",
        "# We will run gradient descent for a number of iterations. At each iteration, we compute the loss,\n",
        "#   compute the derivative of the loss with respect to x, and perform the update.\n",
        "for i in range(500):\n",
        "    x = torch.tensor([x], requires_grad=True)\n",
        "\n",
        "    # TODO: Compute the loss as the square of the difference between x and x_f\n",
        "    loss = (x - x_f) ** 2\n",
        "\n",
        "    # Backpropagate through the loss to compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Update x with gradient descent\n",
        "    x = x.item() - learning_rate * x.grad\n",
        "\n",
        "    history.append(x.item())\n",
        "\n",
        "# Plot the evolution of x as we optimize toward x_f!\n",
        "plt.plot(history)\n",
        "plt.plot([0, 500], [x_f, x_f])\n",
        "plt.legend(('Predicted', 'True'))\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('x value')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC7czCwk3ceH"
      },
      "source": [
        "Now, we have covered the fundamental concepts of PyTorch -- tensors, operations, neural networks, and automatic differentiation. Fire!!\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WBk0ZDWY-ff8"
      ],
      "name": "PT_Part1_Intro.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}